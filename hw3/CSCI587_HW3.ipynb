{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynMhPmd5_0Rk"
      },
      "source": [
        "# Assignment 3: Spatiotemporal Traffic Forecasting using DCRNN\n",
        "\n",
        "### Introduction\n",
        "\n",
        "In this assignment, you will use LA traffic sensor data to explore how different graph structures impact the performance of the [Diffusion Convolutional Recurrent Neural Network (DCRNN)](https://arxiv.org/abs/1707.01926) for traffic forecasting. By the end of this assignment, you should have a deeper understanding of:\n",
        "1. How different graph structures can influence forecasting accuracy of GNN-based approaches.\n",
        "2. How to design an end-to-end approach to train and evaluate a model for spatiotemporal forecasting.\n",
        "\n",
        "### Objectives\n",
        "\n",
        "You will:\n",
        "- Train and test the DCRNN on several graph structures, including:\n",
        "  - **Euclidean Distance**: Graph nodes are connected based on the Euclidean distances between traffic sensors.\n",
        "  - **Road-Network Distance**: Graph nodes are connected based on actual road-network distances between sensors.\n",
        "  - **Fully Connected**: All nodes are connected to each other.\n",
        "  - **Fully Disconnected (Identity Matrix)**: Each node is only connected to itself, meaning the model does not leverage information from neighboring nodes for predictions.\n",
        "  - **Correlation across Time Series**: Connections are based on correlation in traffic patterns across sensors. This means the graph changes dynamically per each time window.\n",
        "\n",
        "- Compare the model performance across these structures.\n",
        "- Analyze why certain graph structures may perform better than others for forecasting traffic patterns.\n",
        "\n",
        "### Dataset Overview\n",
        "\n",
        "The dataset consists of traffic flow readings (average speed of cars passing the sensors over a specific time interval) from various sensors across LA. Each sensor represents a node, and traffic flow measurements are recorded at regular time intervals, providing a temporal sequence for each node.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "Fill in the missing code sections and write your explanations/analysis as required to complete the tasks. Good luck and have fun! Don't forget you can always reach out to the TAs if you need clarifications on the following tasks.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBYyaTCnB6hp"
      },
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "In this section, you will load the METR-LA traffic dataset and preprocess it to prepare it for model input. METR-LA consists of traffic speed data from sensors across Los Angeles County, recorded at 5-minute intervals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKt6xjL6DJo-",
        "outputId": "e1523905-247a-4d84-b1a7-6aa1f72cd0e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files downloaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "# URLs for the data files\n",
        "sensors_url = \"https://github.com/tijsmaas/TrafficPrediction/raw/master/data/metr-la/graph_sensor_locations.csv\"\n",
        "traffic_url = \"https://github.com/TrafficGCN/ST-GCN/raw/refs/heads/main/data/metr-la/traffic/speed.csv\"\n",
        "\n",
        "# Download and save the sensor locations data\n",
        "csv_response = requests.get(sensors_url)\n",
        "with open(\"graph_sensor_locations.csv\", \"wb\") as f:\n",
        "    f.write(csv_response.content)\n",
        "\n",
        "# Download and save the traffic data\n",
        "csv_response = requests.get(traffic_url)\n",
        "with open(\"metr-la.csv\", \"wb\") as f:\n",
        "    f.write(csv_response.content)\n",
        "\n",
        "print(\"Files downloaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9naVj4gKjTj",
        "outputId": "cf6b88c6-06d2-453e-adfd-4be0d2ad1846"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sensor Locations Data:\n",
            "    index  sensor_id  latitude  longitude\n",
            "0      0     773869  34.15497 -118.31829\n",
            "1      1     767541  34.11621 -118.23799\n",
            "2      2     767542  34.11641 -118.23819\n",
            "3      3     717447  34.07248 -118.26772\n",
            "4      4     717446  34.07142 -118.26572\n",
            "\n",
            "Traffic Data:\n",
            "          DATETIMESTAMP     773869     767541     767542     717447     717446  \\\n",
            "0  2012-03-01 00:00:00  64.375000  67.625000  67.125000  61.500000  66.875000   \n",
            "1  2012-03-01 00:05:00  62.666667  68.555556  65.444444  62.444444  64.444444   \n",
            "2  2012-03-01 00:10:00  64.000000  63.750000  60.000000  59.000000  66.500000   \n",
            "3  2012-03-01 00:25:00  57.333333  69.000000  67.666667  61.666667  67.333333   \n",
            "4  2012-03-01 00:30:00  66.500000  63.875000  67.875000  62.375000  64.375000   \n",
            "\n",
            "      717445     773062     767620     737529  ...     772167  769372  \\\n",
            "0  68.750000  65.125000  67.125000  59.625000  ...  45.625000  65.500   \n",
            "1  68.111111  65.000000  65.000000  57.444444  ...  50.666667  69.875   \n",
            "2  66.250000  64.500000  64.250000  63.875000  ...  44.125000  69.000   \n",
            "3  69.000000  60.666667  67.333333  63.000000  ...  42.000000  70.000   \n",
            "4  67.750000  65.125000  64.875000  56.250000  ...  41.250000  69.375   \n",
            "\n",
            "      774204     769806  717590     717592     717595     772168     718141  \\\n",
            "0  64.500000  66.428571  66.875  59.375000  69.000000  59.250000  69.000000   \n",
            "1  66.666667  58.555556  62.000  61.111111  64.444444  55.888889  68.444444   \n",
            "2  56.500000  59.250000  68.125  62.500000  65.625000  61.375000  69.857143   \n",
            "3  68.333333  57.333333  66.000  54.666667  64.666667  57.666667  69.000000   \n",
            "4  59.500000  44.625000  64.250  62.625000  65.500000  51.000000  69.375000   \n",
            "\n",
            "      769373  \n",
            "0  61.875000  \n",
            "1  62.875000  \n",
            "2  62.000000  \n",
            "3  57.333333  \n",
            "4  61.250000  \n",
            "\n",
            "[5 rows x 208 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the sensor locations CSV file\n",
        "sensor_locations = pd.read_csv(\"graph_sensor_locations.csv\")\n",
        "print(\"Sensor Locations Data:\\n\", sensor_locations.head())\n",
        "\n",
        "# Load the METR-LA traffic data\n",
        "traffic_df = pd.read_csv(\"metr-la.csv\")\n",
        "print(\"\\nTraffic Data:\\n\", traffic_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zz_Va5RJO6q-",
        "outputId": "c853c360-6f1b-4dcd-c17e-c437501dfca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unnormalized Sensor Data:\n",
            "       773869     767541     767542     717447     717446     717445  \\\n",
            "0  64.375000  67.625000  67.125000  61.500000  66.875000  68.750000   \n",
            "1  62.666667  68.555556  65.444444  62.444444  64.444444  68.111111   \n",
            "2  64.000000  63.750000  60.000000  59.000000  66.500000  66.250000   \n",
            "3  57.333333  69.000000  67.666667  61.666667  67.333333  69.000000   \n",
            "4  66.500000  63.875000  67.875000  62.375000  64.375000  67.750000   \n",
            "\n",
            "      773062     767620     737529     717816  ...     772167  769372  \\\n",
            "0  65.125000  67.125000  59.625000  62.750000  ...  45.625000  65.500   \n",
            "1  65.000000  65.000000  57.444444  63.333333  ...  50.666667  69.875   \n",
            "2  64.500000  64.250000  63.875000  65.375000  ...  44.125000  69.000   \n",
            "3  60.666667  67.333333  63.000000  63.333333  ...  42.000000  70.000   \n",
            "4  65.125000  64.875000  56.250000  63.000000  ...  41.250000  69.375   \n",
            "\n",
            "      774204     769806  717590     717592     717595     772168     718141  \\\n",
            "0  64.500000  66.428571  66.875  59.375000  69.000000  59.250000  69.000000   \n",
            "1  66.666667  58.555556  62.000  61.111111  64.444444  55.888889  68.444444   \n",
            "2  56.500000  59.250000  68.125  62.500000  65.625000  61.375000  69.857143   \n",
            "3  68.333333  57.333333  66.000  54.666667  64.666667  57.666667  69.000000   \n",
            "4  59.500000  44.625000  64.250  62.625000  65.500000  51.000000  69.375000   \n",
            "\n",
            "      769373  \n",
            "0  61.875000  \n",
            "1  62.875000  \n",
            "2  62.000000  \n",
            "3  57.333333  \n",
            "4  61.250000  \n",
            "\n",
            "[5 rows x 207 columns]\n",
            "datetime Data:\n",
            " 0    2012-03-01 00:00:00\n",
            "1    2012-03-01 00:05:00\n",
            "2    2012-03-01 00:10:00\n",
            "3    2012-03-01 00:25:00\n",
            "4    2012-03-01 00:30:00\n",
            "Name: DATETIMESTAMP, dtype: object\n",
            "\n",
            "\n",
            "Normalized Traffic Data:\n",
            "          DATETIMESTAMP    773869    767541    767542    717447    717446  \\\n",
            "0  2012-03-01 00:00:00  0.919643  0.966071  0.958929  0.878571  0.955357   \n",
            "1  2012-03-01 00:05:00  0.895238  0.979365  0.934921  0.892063  0.920635   \n",
            "2  2012-03-01 00:10:00  0.914286  0.910714  0.857143  0.842857  0.950000   \n",
            "3  2012-03-01 00:25:00  0.819048  0.985714  0.966667  0.880952  0.961905   \n",
            "4  2012-03-01 00:30:00  0.950000  0.912500  0.969643  0.891071  0.919643   \n",
            "\n",
            "     717445    773062    767620    737529  ...    772167    769372    774204  \\\n",
            "0  0.982143  0.930357  0.958929  0.851786  ...  0.701923  0.935714  0.921429   \n",
            "1  0.973016  0.928571  0.928571  0.820635  ...  0.779487  0.998214  0.952381   \n",
            "2  0.946429  0.921429  0.917857  0.912500  ...  0.678846  0.985714  0.807143   \n",
            "3  0.985714  0.866667  0.961905  0.900000  ...  0.646154  1.000000  0.976190   \n",
            "4  0.967857  0.930357  0.926786  0.803571  ...  0.634615  0.991071  0.850000   \n",
            "\n",
            "     769806    717590    717592    717595    772168    718141    769373  \n",
            "0  0.948980  0.955357  0.848214  0.985714  0.846429  0.985714  0.883929  \n",
            "1  0.836508  0.885714  0.873016  0.920635  0.798413  0.977778  0.898214  \n",
            "2  0.846429  0.973214  0.892857  0.937500  0.876786  0.997959  0.885714  \n",
            "3  0.819048  0.942857  0.780952  0.923810  0.823810  0.985714  0.819048  \n",
            "4  0.637500  0.917857  0.894643  0.935714  0.728571  0.991071  0.875000  \n",
            "\n",
            "[5 rows x 208 columns]\n"
          ]
        }
      ],
      "source": [
        "# Separate the datetime column from the sensor data\n",
        "datetime_column = traffic_df.iloc[:, 0]  # the first column is datetime\n",
        "sensor_data = traffic_df.iloc[:, 1:]  # All other columns are sensor data\n",
        "print(\"Unnormalized Sensor Data:\\n\", sensor_data.head())\n",
        "print(\"datetime Data:\\n\", datetime_column.head())\n",
        "\n",
        "# Normalize the traffic speed\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "normalized_sensor_data = scaler.fit_transform(sensor_data)\n",
        "\n",
        "# Convert normalized data back to a DataFrame\n",
        "normalized_sensor_df = pd.DataFrame(normalized_sensor_data, columns=sensor_data.columns)\n",
        "\n",
        "# Add back the datetime column just in case\n",
        "normalized_traffic_df = pd.concat([datetime_column, normalized_sensor_df], axis=1)\n",
        "print(\"\\n\\nNormalized Traffic Data:\\n\", normalized_traffic_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU5Ope5Dr32d"
      },
      "source": [
        "Next, we define a dataset class so as to manage the traffic samples more easily for training DCRNN. This class basically prepares windows of traffic observations as the input to the model, and provides the ground truth future traffic observations for the specified horizon to calculate the forecasting error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CFutQ0HzSf1C"
      },
      "outputs": [],
      "source": [
        "# Here, we define a traffic dataset class to easily get METR-LA samples\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "\n",
        "class TrafficDataset(Dataset):\n",
        "    def __init__(self, traffic_df, sensor_df, window_size, horizon):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            traffic_df (pd.DataFrame): Normalized traffic data with datetime as the first column.\n",
        "            sensor_df (pd.DataFrame): Sensor locations or metadata.\n",
        "            window_size (int): Number of time steps in each input sequence.\n",
        "            horizon (int): Number of time steps ahead to predict.\n",
        "        \"\"\"\n",
        "        self.datetime = traffic_df.iloc[:, 0]  # Store datetime separately just in case\n",
        "        self.data = traffic_df.iloc[:, 1:].values.reshape(-1, traffic_df.shape[1] - 1, 1)  # Shape (num_samples, num_sensors, num_features)\n",
        "\n",
        "        # Store sensor locations data for future adjacency calculations\n",
        "        self.sensor_df = sensor_df\n",
        "\n",
        "        # Sliding window and horizon\n",
        "        self.window_size = window_size\n",
        "        self.horizon = horizon\n",
        "\n",
        "    def __len__(self):\n",
        "        # Total samples is reduced by window size + horizon to ensure complete sequences\n",
        "        return len(self.data) - self.window_size - self.horizon + 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Define input window (past sequence) and target (future value)\n",
        "        x = self.data[idx : idx + self.window_size]\n",
        "        y = self.data[idx + self.window_size : idx + self.window_size + self.horizon]\n",
        "\n",
        "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seC0Fbe0sNEb"
      },
      "source": [
        "In the next step, we divide the traffic data into train/validation/test folds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8j08eVgT-ZP",
        "outputId": "532a889a-2687-4487-b87c-c14c791a46e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (22491, 208)\n",
            "Validation data shape: (4830, 208)\n",
            "Test data shape: (4831, 208)\n"
          ]
        }
      ],
      "source": [
        "# Next, we split the data into train/val/test\n",
        "window_size = 12\n",
        "horizon = 3\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Calculate split indices\n",
        "num_samples = len(traffic_df) - window_size - horizon + 1\n",
        "train_size = int(train_ratio * num_samples)\n",
        "val_size = int(val_ratio * num_samples)\n",
        "\n",
        "# Split the traffic data into train, validation, and test sets\n",
        "train_data = traffic_df.iloc[:train_size + window_size + horizon - 1]\n",
        "val_data = traffic_df.iloc[train_size:train_size + val_size + window_size + horizon - 1]\n",
        "test_data = traffic_df.iloc[train_size + val_size:]\n",
        "\n",
        "print(f\"Training data shape: {train_data.shape}\")\n",
        "print(f\"Validation data shape: {val_data.shape}\")\n",
        "print(f\"Test data shape: {test_data.shape}\")\n",
        "\n",
        "# Initialize dataset instances\n",
        "train_dataset = TrafficDataset(traffic_df=train_data, sensor_df=sensor_locations, window_size=window_size, horizon=horizon)\n",
        "val_dataset = TrafficDataset(traffic_df=val_data, sensor_df=sensor_locations, window_size=window_size, horizon=horizon)\n",
        "test_dataset = TrafficDataset(traffic_df=test_data, sensor_df=sensor_locations, window_size=window_size, horizon=horizon)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo8yfd_-seu-"
      },
      "source": [
        "Next, we initialize data loaders to get batches of samples from datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKhWJbKVUOAw",
        "outputId": "829bdf71-8e44-4ddd-da0f-31c7ca3536c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training batches: 703\n",
            "Number of validation batches: 151\n",
            "Number of test batches: 151\n"
          ]
        }
      ],
      "source": [
        "# Here, we set up our dataloaders\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Create DataLoaders for each dataset\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Number of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of validation batches: {len(val_loader)}\")\n",
        "print(f\"Number of test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mguzuFJ2X_z_"
      },
      "source": [
        "### Model\n",
        "Here, we add the DCRNN model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0NuZIiUeUcGX"
      },
      "outputs": [],
      "source": [
        "# Next, we set up the DCRNN model\n",
        "\"\"\"\n",
        "Codes are adapted from https://github.com/liyaguang/DCRNN\n",
        "and https://github.com/xlwang233/pytorch-DCRNN and https://github.com/tsy935/eeg-gnn-ssl, which are\n",
        "licensed under the MIT License.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def compute_sampling_threshold(cl_decay_steps, global_step):\n",
        "    \"\"\"\n",
        "    Compute scheduled sampling threshold\n",
        "    \"\"\"\n",
        "    return cl_decay_steps / \\\n",
        "        (cl_decay_steps + np.exp(global_step / cl_decay_steps))\n",
        "\n",
        "\n",
        "class DiffusionGraphConv(nn.Module):\n",
        "    def __init__(self, num_supports, input_dim, hid_dim, num_nodes,\n",
        "                 max_diffusion_step, output_dim, bias_start=0.0,\n",
        "                 filter_type='laplacian'):\n",
        "        \"\"\"\n",
        "        Diffusion graph convolution\n",
        "        Args:\n",
        "            num_supports: number of supports, 1 for 'laplacian' filter and 2\n",
        "                for 'dual_random_walk'\n",
        "            input_dim: input feature dim\n",
        "            hid_dim: hidden units\n",
        "            num_nodes: number of nodes in graph\n",
        "            max_diffusion_step: maximum diffusion step\n",
        "            output_dim: output feature dim\n",
        "            filter_type: 'laplacian' for undirected graph, and 'dual_random_walk'\n",
        "                for directed graph\n",
        "        \"\"\"\n",
        "        super(DiffusionGraphConv, self).__init__()\n",
        "        num_matrices = num_supports * max_diffusion_step + 1\n",
        "        self._input_size = input_dim + hid_dim\n",
        "        self._num_nodes = num_nodes\n",
        "        self._max_diffusion_step = max_diffusion_step\n",
        "        self._filter_type = filter_type\n",
        "        self.weight = nn.Parameter(\n",
        "            torch.FloatTensor(\n",
        "                size=(\n",
        "                    self._input_size *\n",
        "                    num_matrices,\n",
        "                    output_dim)))\n",
        "        self.biases = nn.Parameter(torch.FloatTensor(size=(output_dim,)))\n",
        "        nn.init.xavier_normal_(self.weight.data, gain=1.414)\n",
        "        nn.init.constant_(self.biases.data, val=bias_start)\n",
        "\n",
        "    @staticmethod\n",
        "    def _concat(x, x_):\n",
        "        x_ = torch.unsqueeze(x_, 1)\n",
        "        return torch.cat([x, x_], dim=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def _build_sparse_matrix(L):\n",
        "        \"\"\"\n",
        "        build pytorch sparse tensor from scipy sparse matrix\n",
        "        reference: https://stackoverflow.com/questions/50665141\n",
        "        \"\"\"\n",
        "        shape = L.shape\n",
        "        i = torch.LongTensor(np.vstack((L.row, L.col)).astype(int))\n",
        "        v = torch.FloatTensor(L.data)\n",
        "        return torch.sparse.FloatTensor(i, v, torch.Size(shape))\n",
        "\n",
        "    def forward(self, supports, inputs, state, output_size, bias_start=0.0):\n",
        "        # Reshape input and state to (batch_size, num_nodes,\n",
        "        # input_dim/hidden_dim)\n",
        "        batch_size = inputs.shape[0]\n",
        "        inputs = torch.reshape(inputs, (batch_size, self._num_nodes, -1))\n",
        "        state = torch.reshape(state, (batch_size, self._num_nodes, -1))\n",
        "        # (batch, num_nodes, input_dim+hidden_dim)\n",
        "        inputs_and_state = torch.cat([inputs, state], dim=2)\n",
        "        input_size = self._input_size\n",
        "\n",
        "        x0 = inputs_and_state  # (batch, num_nodes, input_dim+hidden_dim)\n",
        "        # (batch, 1, num_nodes, input_dim+hidden_dim)\n",
        "        x = torch.unsqueeze(x0, dim=1)\n",
        "\n",
        "        if self._max_diffusion_step == 0:\n",
        "            pass\n",
        "        else:\n",
        "            for support in supports:\n",
        "                # (batch, num_nodes, input_dim+hidden_dim)\n",
        "                x1 = torch.matmul(support, x0)\n",
        "                # (batch, ?, num_nodes, input_dim+hidden_dim)\n",
        "                x = self._concat(x, x1)\n",
        "                for k in range(2, self._max_diffusion_step + 1):\n",
        "                    # (batch, num_nodes, input_dim+hidden_dim)\n",
        "                    x2 = 2 * torch.matmul(support, x1) - x0\n",
        "                    x = self._concat(\n",
        "                        x, x2)  # (batch, ?, num_nodes, input_dim+hidden_dim)\n",
        "                    x1, x0 = x2, x1\n",
        "\n",
        "        num_matrices = len(supports) * \\\n",
        "            self._max_diffusion_step + 1  # Adds for x itself\n",
        "        # (batch, num_nodes, num_matrices, input_hidden_size)\n",
        "        x = torch.transpose(x, dim0=1, dim1=2)\n",
        "        # (batch, num_nodes, input_hidden_size, num_matrices)\n",
        "        x = torch.transpose(x, dim0=2, dim1=3)\n",
        "        x = torch.reshape(\n",
        "            x,\n",
        "            shape=[\n",
        "                batch_size,\n",
        "                self._num_nodes,\n",
        "                input_size *\n",
        "                num_matrices])\n",
        "        x = torch.reshape(\n",
        "            x,\n",
        "            shape=[\n",
        "                batch_size *\n",
        "                self._num_nodes,\n",
        "                input_size *\n",
        "                num_matrices])\n",
        "        # (batch_size * self._num_nodes, output_size)\n",
        "        x = torch.matmul(x, self.weight)\n",
        "        x = torch.add(x, self.biases)\n",
        "        return torch.reshape(x, [batch_size, self._num_nodes * output_size])\n",
        "\n",
        "\n",
        "class DCGRUCell(nn.Module):\n",
        "    \"\"\"\n",
        "    Graph Convolution Gated Recurrent Unit Cell.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            input_dim,\n",
        "            num_units,\n",
        "            max_diffusion_step,\n",
        "            num_nodes,\n",
        "            filter_type=\"laplacian\",\n",
        "            nonlinearity='tanh',\n",
        "            use_gc_for_ru=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_dim: input feature dim\n",
        "            num_units: number of DCGRU hidden units\n",
        "            max_diffusion_step: maximum diffusion step\n",
        "            num_nodes: number of nodes in the graph\n",
        "            filter_type: 'laplacian' for undirected graph, 'dual_random_walk' for directed graph\n",
        "            nonlinearity: 'tanh' or 'relu'. Default is 'tanh'\n",
        "            use_gc_for_ru: decide whether to use graph convolution inside rnn. Default True\n",
        "        \"\"\"\n",
        "        super(DCGRUCell, self).__init__()\n",
        "        self._activation = torch.tanh if nonlinearity == 'tanh' else torch.relu\n",
        "        self._num_nodes = num_nodes\n",
        "        self._num_units = num_units\n",
        "        self._max_diffusion_step = max_diffusion_step\n",
        "        self._use_gc_for_ru = use_gc_for_ru\n",
        "        if filter_type == \"laplacian\":  # ChebNet graph conv\n",
        "            self._num_supports = 1\n",
        "        elif filter_type == \"random_walk\":  # Forward random walk\n",
        "            self._num_supports = 1\n",
        "        elif filter_type == \"dual_random_walk\":  # Bidirectional random walk\n",
        "            self._num_supports = 2\n",
        "        else:\n",
        "            self._num_supports = 1\n",
        "\n",
        "        self.dconv_gate = DiffusionGraphConv(\n",
        "            num_supports=self._num_supports,\n",
        "            input_dim=input_dim,\n",
        "            hid_dim=num_units,\n",
        "            num_nodes=num_nodes,\n",
        "            max_diffusion_step=max_diffusion_step,\n",
        "            output_dim=num_units * 2,\n",
        "            filter_type=filter_type)\n",
        "        self.dconv_candidate = DiffusionGraphConv(\n",
        "            num_supports=self._num_supports,\n",
        "            input_dim=input_dim,\n",
        "            hid_dim=num_units,\n",
        "            num_nodes=num_nodes,\n",
        "            max_diffusion_step=max_diffusion_step,\n",
        "            output_dim=num_units,\n",
        "            filter_type=filter_type)\n",
        "\n",
        "    @property\n",
        "    def output_size(self):\n",
        "        output_size = self._num_nodes * self._num_units\n",
        "        return output_size\n",
        "\n",
        "    def forward(self, supports, inputs, state):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: (B, num_nodes * input_dim)\n",
        "            state: (B, num_nodes * num_units)\n",
        "        Returns:\n",
        "            output: (B, num_nodes * output_dim)\n",
        "            state: (B, num_nodes * num_units)\n",
        "        \"\"\"\n",
        "        output_size = 2 * self._num_units\n",
        "        if self._use_gc_for_ru:\n",
        "            fn = self.dconv_gate\n",
        "        else:\n",
        "            fn = self._fc\n",
        "        value = torch.sigmoid(\n",
        "            fn(supports, inputs, state, output_size, bias_start=1.0))\n",
        "        value = torch.reshape(value, (-1, self._num_nodes, output_size))\n",
        "        r, u = torch.split(\n",
        "            value, split_size_or_sections=int(\n",
        "                output_size / 2), dim=-1)\n",
        "        r = torch.reshape(r, (-1, self._num_nodes * self._num_units))\n",
        "        u = torch.reshape(u, (-1, self._num_nodes * self._num_units))\n",
        "        # batch_size, self._num_nodes * output_size\n",
        "        c = self.dconv_candidate(supports, inputs, r * state, self._num_units)\n",
        "        if self._activation is not None:\n",
        "            c = self._activation(c)\n",
        "        output = new_state = u * state + (1 - u) * c\n",
        "\n",
        "        return output, new_state\n",
        "\n",
        "    @staticmethod\n",
        "    def _concat(x, x_):\n",
        "        x_ = torch.unsqueeze(x_, 0)\n",
        "        return torch.cat([x, x_], dim=0)\n",
        "\n",
        "    def _gconv(self, supports, inputs, state, output_size, bias_start=0.0):\n",
        "        pass\n",
        "\n",
        "    def _fc(self, supports, inputs, state, output_size, bias_start=0.0):\n",
        "        pass\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        # state: (B, num_nodes * num_units)\n",
        "        return torch.zeros(batch_size, self._num_nodes * self._num_units)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DCRNNEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, max_diffusion_step,\n",
        "                 hid_dim, num_nodes, num_rnn_layers,\n",
        "                 dcgru_activation=None, filter_type='laplacian',\n",
        "                 device=None):\n",
        "        super(DCRNNEncoder, self).__init__()\n",
        "        self.hid_dim = hid_dim\n",
        "        self.num_rnn_layers = num_rnn_layers\n",
        "        self._device = device\n",
        "\n",
        "        encoding_cells = list()\n",
        "        # the first layer has different input_dim\n",
        "        encoding_cells.append(\n",
        "            DCGRUCell(\n",
        "                input_dim=input_dim,\n",
        "                num_units=hid_dim,\n",
        "                max_diffusion_step=max_diffusion_step,\n",
        "                num_nodes=num_nodes,\n",
        "                nonlinearity=dcgru_activation,\n",
        "                filter_type=filter_type))\n",
        "\n",
        "        # construct multi-layer rnn\n",
        "        for _ in range(1, num_rnn_layers):\n",
        "            encoding_cells.append(\n",
        "                DCGRUCell(\n",
        "                    input_dim=hid_dim,\n",
        "                    num_units=hid_dim,\n",
        "                    max_diffusion_step=max_diffusion_step,\n",
        "                    num_nodes=num_nodes,\n",
        "                    nonlinearity=dcgru_activation,\n",
        "                    filter_type=filter_type))\n",
        "        self.encoding_cells = nn.ModuleList(encoding_cells)\n",
        "\n",
        "    def forward(self, inputs, initial_hidden_state, supports):\n",
        "        seq_length = inputs.shape[0]\n",
        "        batch_size = inputs.shape[1]\n",
        "        # (seq_length, batch_size, num_nodes*input_dim)\n",
        "        inputs = torch.reshape(inputs, (seq_length, batch_size, -1))\n",
        "\n",
        "        current_inputs = inputs\n",
        "        # the output hidden states, shape (num_layers, batch, outdim)\n",
        "        output_hidden = []\n",
        "        for i_layer in range(self.num_rnn_layers):\n",
        "            hidden_state = initial_hidden_state[i_layer]\n",
        "            output_inner = []\n",
        "            for t in range(seq_length):\n",
        "                _, hidden_state = self.encoding_cells[i_layer](\n",
        "                    supports, current_inputs[t, ...], hidden_state)\n",
        "                output_inner.append(hidden_state)\n",
        "            output_hidden.append(hidden_state)\n",
        "            current_inputs = torch.stack(output_inner, dim=0).to(\n",
        "                self._device)  # (seq_len, batch_size, num_nodes * rnn_units)\n",
        "        output_hidden = torch.stack(output_hidden, dim=0).to(\n",
        "            self._device)  # (num_layers, batch_size, num_nodes * rnn_units)\n",
        "        return output_hidden, current_inputs\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        init_states = []\n",
        "        for i in range(self.num_rnn_layers):\n",
        "            init_states.append(self.encoding_cells[i].init_hidden(batch_size))\n",
        "        # (num_layers, batch_size, num_nodes * rnn_units)\n",
        "        return torch.stack(init_states, dim=0)\n",
        "\n",
        "\n",
        "class DCGRUDecoder(nn.Module):\n",
        "    def __init__(self, input_dim, max_diffusion_step, num_nodes,\n",
        "                 hid_dim, output_dim, num_rnn_layers, dcgru_activation=None,\n",
        "                 filter_type='laplacian', device=None, dropout=0.0):\n",
        "        super(DCGRUDecoder, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hid_dim = hid_dim\n",
        "        self.num_nodes = num_nodes\n",
        "        self.output_dim = output_dim\n",
        "        self.num_rnn_layers = num_rnn_layers\n",
        "        self._device = device\n",
        "        self.dropout = dropout\n",
        "\n",
        "        cell = DCGRUCell(input_dim=hid_dim, num_units=hid_dim,\n",
        "                         max_diffusion_step=max_diffusion_step,\n",
        "                         num_nodes=num_nodes, nonlinearity=dcgru_activation,\n",
        "                         filter_type=filter_type)\n",
        "\n",
        "        decoding_cells = list()\n",
        "        # first layer of the decoder\n",
        "        decoding_cells.append(\n",
        "            DCGRUCell(\n",
        "                input_dim=input_dim,\n",
        "                num_units=hid_dim,\n",
        "                max_diffusion_step=max_diffusion_step,\n",
        "                num_nodes=num_nodes,\n",
        "                nonlinearity=dcgru_activation,\n",
        "                filter_type=filter_type))\n",
        "        # construct multi-layer rnn\n",
        "        for _ in range(1, num_rnn_layers):\n",
        "            decoding_cells.append(cell)\n",
        "\n",
        "        self.decoding_cells = nn.ModuleList(decoding_cells)\n",
        "        self.projection_layer = nn.Linear(self.hid_dim, self.output_dim)\n",
        "        self.dropout = nn.Dropout(p=dropout)  # dropout before projection layer\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            inputs,\n",
        "            initial_hidden_state,\n",
        "            supports,\n",
        "            teacher_forcing_ratio=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            inputs: shape (seq_len, batch_size, num_nodes, output_dim)\n",
        "            initial_hidden_state: the last hidden state of the encoder, shape (num_layers, batch, num_nodes * rnn_units)\n",
        "            supports: list of supports from laplacian or dual_random_walk filters\n",
        "            teacher_forcing_ratio: ratio for teacher forcing\n",
        "        Returns:\n",
        "            outputs: shape (seq_len, batch_size, num_nodes * output_dim)\n",
        "        \"\"\"\n",
        "        seq_length, batch_size, _, _ = inputs.shape\n",
        "        inputs = torch.reshape(inputs, (seq_length, batch_size, -1))\n",
        "\n",
        "        go_symbol = torch.zeros(\n",
        "            (batch_size,\n",
        "             self.num_nodes *\n",
        "             self.output_dim)).to(\n",
        "            self._device)\n",
        "\n",
        "        # tensor to store decoder outputs\n",
        "        outputs = torch.zeros(\n",
        "            seq_length,\n",
        "            batch_size,\n",
        "            self.num_nodes *\n",
        "            self.output_dim).to(\n",
        "            self._device)\n",
        "\n",
        "        current_input = go_symbol  # (batch_size, num_nodes * input_dim)\n",
        "        for t in range(seq_length):\n",
        "            next_input_hidden_state = []\n",
        "            for i_layer in range(0, self.num_rnn_layers):\n",
        "                hidden_state = initial_hidden_state[i_layer]\n",
        "                output, hidden_state = self.decoding_cells[i_layer](\n",
        "                    supports, current_input, hidden_state)\n",
        "                current_input = output\n",
        "                next_input_hidden_state.append(hidden_state)\n",
        "            initial_hidden_state = torch.stack(next_input_hidden_state, dim=0)\n",
        "\n",
        "            projected = self.projection_layer(self.dropout(\n",
        "                output.reshape(batch_size, self.num_nodes, -1)))\n",
        "            projected = projected.reshape(\n",
        "                batch_size, self.num_nodes * self.output_dim)\n",
        "            outputs[t] = projected\n",
        "\n",
        "            if teacher_forcing_ratio is not None:\n",
        "                teacher_force = random.random() < teacher_forcing_ratio  # a bool value\n",
        "                current_input = (inputs[t] if teacher_force else projected)\n",
        "            else:\n",
        "                current_input = projected\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "\n",
        "########## Model for next time prediction ##########\n",
        "class DCRNNModel_nextTimePred(nn.Module):\n",
        "    def __init__(self, num_nodes, hidden_dim,\n",
        "                 input_dim, output_dim,\n",
        "                max_diffusion_step=2, num_rnn_layers=1,\n",
        "                cl_decay_steps=3000, dcgru_activation='tanh',\n",
        "                filter_type='laplacian', dropout=0.0,\n",
        "                use_curriculum_learning=False,\n",
        "                device=None):\n",
        "        super(DCRNNModel_nextTimePred, self).__init__()\n",
        "\n",
        "\n",
        "        self.num_nodes = num_nodes\n",
        "        self.num_rnn_layers = num_rnn_layers\n",
        "        self.rnn_units = hidden_dim\n",
        "        self._device = device\n",
        "        self.output_dim = output_dim\n",
        "        self.cl_decay_steps = cl_decay_steps # sampling decay steps\n",
        "        self.use_curriculum_learning = bool(use_curriculum_learning)\n",
        "\n",
        "        self.encoder = DCRNNEncoder(input_dim=input_dim,\n",
        "                                    max_diffusion_step=max_diffusion_step,\n",
        "                                    hid_dim=self.rnn_units, num_nodes=num_nodes,\n",
        "                                    num_rnn_layers=num_rnn_layers,\n",
        "                                    dcgru_activation=dcgru_activation,\n",
        "                                    filter_type=filter_type)\n",
        "        self.decoder = DCGRUDecoder(input_dim=output_dim,\n",
        "                                    max_diffusion_step=max_diffusion_step,\n",
        "                                    num_nodes=num_nodes, hid_dim=self.rnn_units,\n",
        "                                    output_dim=output_dim,\n",
        "                                    num_rnn_layers=num_rnn_layers,\n",
        "                                    dcgru_activation=dcgru_activation,\n",
        "                                    filter_type=filter_type,\n",
        "                                    device=device,\n",
        "                                    dropout=dropout)\n",
        "\n",
        "    def forward(\n",
        "            self,\n",
        "            encoder_inputs,\n",
        "            decoder_inputs,\n",
        "            supports,\n",
        "            batches_seen=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            encoder_inputs: encoder input sequence, shape (batch, input_seq_len, num_nodes, input_dim)\n",
        "            decoder_inputs: decoder input sequence, shape (batch, output_seq_len, num_nodes, output_dim)\n",
        "            supports: list of adjacency matrices, with length of batch and each element shape (num_nodes, num_nodes)\n",
        "            batches_seen: number of examples seen so far, for teacher forcing\n",
        "        Returns:\n",
        "            outputs: predicted output sequence, shape (batch, output_seq_len, num_nodes, output_dim)\n",
        "        \"\"\"\n",
        "        batch_size, output_seq_len, num_nodes, _ = decoder_inputs.shape\n",
        "        # supports = [support.repeat(batch_size, 1, 1) for support in supports]\n",
        "        if supports[0].shape[0] != batch_size:\n",
        "            supports = [supports[0][0, :, :].repeat(batch_size, 1, 1)]\n",
        "            print(supports[0].shape, len(supports))\n",
        "\n",
        "        # (seq_len, batch_size, num_nodes, input_dim)\n",
        "        encoder_inputs = torch.transpose(encoder_inputs, dim0=0, dim1=1)\n",
        "        # (seq_len, batch_size, num_nodes, output_dim)\n",
        "        decoder_inputs = torch.transpose(decoder_inputs, dim0=0, dim1=1)\n",
        "\n",
        "        # initialize the hidden state of the encoder\n",
        "        init_hidden_state = self.encoder.init_hidden(batch_size).to(self._device)\n",
        "\n",
        "        # encoder\n",
        "        # (num_layers, batch, rnn_units*num_nodes)\n",
        "        encoder_hidden_state, _ = self.encoder(\n",
        "            encoder_inputs, init_hidden_state, supports)\n",
        "\n",
        "        # decoder\n",
        "        if self.training and self.use_curriculum_learning and (\n",
        "                batches_seen is not None):\n",
        "            teacher_forcing_ratio = compute_sampling_threshold(\n",
        "                self.cl_decay_steps, batches_seen)\n",
        "        else:\n",
        "            teacher_forcing_ratio = None\n",
        "        outputs = self.decoder(\n",
        "            decoder_inputs,\n",
        "            encoder_hidden_state,\n",
        "            supports,\n",
        "            teacher_forcing_ratio=teacher_forcing_ratio)  # (seq_len, batch_size, num_nodes * output_dim)\n",
        "        # (seq_len, batch_size, num_nodes, output_dim)\n",
        "        outputs = outputs.reshape((output_seq_len, batch_size, num_nodes, -1))\n",
        "        # (batch_size, seq_len, num_nodes, output_dim)\n",
        "        outputs = torch.transpose(outputs, dim0=0, dim1=1)\n",
        "\n",
        "        return outputs\n",
        "########## Model for next time prediction ##########"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_wO7_DeZXce"
      },
      "source": [
        "### Here, you are asked to implement different strategies for building the adjacency matrix of the graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "T2b0cLYhZY-e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance_matrix\n",
        "import osmnx as ox\n",
        "import networkx as nx\n",
        "\n",
        "def calculate_euclidean_adjacency(sensor_locations, threshold):\n",
        "    \"\"\"\n",
        "    Creates an adjacency matrix where nodes are connected based on their Euclidean distance.\n",
        "    Args:\n",
        "        sensor_locations (pd.DataFrame): DataFrame with sensor coordinates (latitude, longitude).\n",
        "        threshold (float): Distance threshold for connectivity; if distance > threshold, set weight to 0.\n",
        "    Returns:\n",
        "        adjacency_matrix (np.array): Adjacency matrix based on Euclidean distances. shape: (num_nodes, num_nodes)\n",
        "    \"\"\"\n",
        "    # TODO: Compute the pairwise Euclidean distance between sensor locations, turn it into similarity scores using Gaussian Kernel\n",
        "    # similar to the approach proposed in the paper\n",
        "    # return the adjacency matrix\n",
        "    # Note: You will need to select a reasonable threshold to result in a reasonably sparse matrix for better performance\n",
        "    coords = sensor_locations[['latitude', 'longitude']].values\n",
        "    dist_matrix = distance_matrix(coords, coords)\n",
        "    sigma = np.std(dist_matrix)\n",
        "    adjacency_matrix = np.exp(- (dist_matrix ** 2) / (sigma ** 2))\n",
        "    adjacency_matrix[dist_matrix > threshold] = 0\n",
        "    return adjacency_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def calculate_road_network_adjacency(sensor_locations, threshold):\n",
        "    \"\"\"\n",
        "    Creates an adjacency matrix based on shortest path distances in a road network.\n",
        "    Args:\n",
        "        sensor_locations (pd.DataFrame): DataFrame with sensor locations.\n",
        "        threshold (float): Maximum path distance to consider a connection.\n",
        "    Returns:\n",
        "        adjacency_matrix (np.array): Adjacency matrix based on road network distances. shape: (num_nodes, num_nodes)\n",
        "    \"\"\"\n",
        "    # TODO: First, you need to find the road network information in LA, then you need to calculate shortest path distances in the road network, turn it into similarity scores using Gaussian Kernel, return the adjacency matrix\n",
        "    # You also need to select a reasonable distance threshold value to result in a reasonably sparse adjacency matrix for better performance\n",
        "    # Tip: To get road-network information, you can use an approach similar to the previous assignment. Alternatively, similar to the original DCRNN paper, you can use `OSRM local server` to find the driving distance between the sensors.\n",
        "    coords = sensor_locations[['latitude', 'longitude']].values\n",
        "    G = ox.graph_from_point(coords.mean(axis=0), dist=20000, network_type='drive')\n",
        "    node_ids = [ox.distance.nearest_nodes(G, x[1], x[0]) for x in coords]\n",
        "    \n",
        "    num_nodes = len(coords)\n",
        "    dist_matrix = np.zeros((num_nodes, num_nodes), dtype=np.float32)\n",
        "\n",
        "    for i in range(num_nodes):\n",
        "        for j in range(num_nodes):\n",
        "            if i == j:\n",
        "                dist_matrix[i, j] = 0\n",
        "            else:\n",
        "                try:\n",
        "                    dist = nx.shortest_path_length(G, node_ids[i], node_ids[j], weight='length')\n",
        "                    dist_matrix[i, j] = dist\n",
        "                except:\n",
        "                    dist_matrix[i, j] = np.inf  # unreachable node\n",
        "\n",
        "    sigma = np.std(dist_matrix[dist_matrix < np.inf])\n",
        "    adjacency_matrix = np.exp(- (dist_matrix ** 2) / (sigma ** 2))\n",
        "    adjacency_matrix[dist_matrix > threshold] = 0\n",
        "    adjacency_matrix[np.isinf(dist_matrix)] = 0\n",
        "    return adjacency_matrix\n",
        "\n",
        "\n",
        "def calculate_fully_connected_adjacency(num_nodes):\n",
        "    \"\"\"\n",
        "    Creates a fully connected adjacency matrix.\n",
        "    Args:\n",
        "        num_nodes (int): Number of nodes in the graph.\n",
        "    Returns:\n",
        "        adjacency_matrix (np.array): Fully connected adjacency matrix with all entries set to 1. shape: (num_nodes, num_nodes)\n",
        "    \"\"\"\n",
        "    # TODO: Create a fully connected matrix with equal weights\n",
        "    adjacency_matrix = np.ones((num_nodes, num_nodes), dtype=np.float32)\n",
        "    np.fill_diagonal(adjacency_matrix, 0)\n",
        "    return adjacency_matrix\n",
        "\n",
        "\n",
        "def calculate_identity_adjacency(num_nodes):\n",
        "    \"\"\"\n",
        "    Creates an identity matrix where only self-loops are present.\n",
        "    Args:\n",
        "        num_nodes (int): Number of nodes in the graph.\n",
        "    Returns:\n",
        "        adjacency_matrix (np.array): Identity matrix. shape: (num_nodes, num_nodes)\n",
        "    \"\"\"\n",
        "    # TODO: Create an identity matrix\n",
        "    return np.eye(num_nodes, dtype=np.float32)\n",
        "\n",
        "\n",
        "def calculate_correlation_adjacency_batch(batch_data, threshold):\n",
        "    \"\"\"\n",
        "    Creates an adjacency matrix for a batch based on the correlation between sensors in the batch.\n",
        "    Args:\n",
        "        batch_data (torch.Tensor): Batch data of shape (batch_size, time_steps, num_nodes, 1).\n",
        "        threshold (float): Minimum correlation required for a connection.\n",
        "    Returns:\n",
        "        adjacency_matrix (torch.Tensor): Correlation-based adjacency matrix for the batch. shape: (batch_size, num_nodes, num_nodes)\n",
        "    \"\"\"\n",
        "    # TODO: calculate the correlations between sensor time series for each sample in the batch\n",
        "    # create an adjacency matrix based on that, get rid of values smaller than a reasonable threshold, return it.\n",
        "    # Tips: There are many different ways to measure similarities between different sequences, some options are cross-correlation, DTW distance, Euclidean distance, Attention mechanism, etc.\n",
        "    # It might also be computationally very slow to calculate these similarities per sample every time during training, you might want to somehow get rid of the repeated calculations across different epochs by caching or some other mechanism.\n",
        "    batch_size, time_steps, num_nodes, _ = batch_data.shape\n",
        "    batch_data = batch_data.squeeze(-1)  # shape: (B, T, N)\n",
        "    adj_batch = torch.zeros((batch_size, num_nodes, num_nodes))\n",
        "\n",
        "    for b in range(batch_size):\n",
        "        data = batch_data[b]  # shape: (T, N)\n",
        "        corr = torch.corrcoef(data.T)  # shape: (N, N)\n",
        "        corr[torch.isnan(corr)] = 0.0\n",
        "        corr[torch.abs(corr) < threshold] = 0.0\n",
        "        adj_batch[b] = corr\n",
        "\n",
        "    return adj_batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGtDMpdybO7u"
      },
      "source": [
        "### Training\n",
        "Next, we set up the train/validation pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k8ELOs4ibK82"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Loss function and metrics\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Helper function for MAE\n",
        "def mean_absolute_error(y_pred, y_true):\n",
        "    return torch.mean(torch.abs(y_pred - y_true))\n",
        "\n",
        "\n",
        "# Training loop with use_corr_based_graph flag\n",
        "def train_epoch(model, train_loader, supports, optimizer, device, use_corr_based_graph):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for batch_idx, (encoder_inputs, decoder_inputs) in enumerate(train_loader):\n",
        "        encoder_inputs, decoder_inputs = encoder_inputs.to(device), decoder_inputs.to(device)\n",
        "\n",
        "        # Conditionally set supports based on use_corr_based_graph flag\n",
        "        if use_corr_based_graph:\n",
        "            # Calculate correlation adjacency matrix for the current batch\n",
        "            supports = [calculate_correlation_adjacency_batch(encoder_inputs).to(device)]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(encoder_inputs, decoder_inputs, supports)\n",
        "        loss = criterion(outputs, decoder_inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    return train_loss / len(train_loader)\n",
        "\n",
        "# Validation loop with use_corr_based_graph flag\n",
        "def validate_epoch(model, val_loader, supports, device, use_corr_based_graph):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_mae = 0.0\n",
        "    with torch.no_grad():\n",
        "        for encoder_inputs, decoder_inputs in val_loader:\n",
        "            encoder_inputs, decoder_inputs = encoder_inputs.to(device), decoder_inputs.to(device)\n",
        "\n",
        "            # Conditionally set supports based on use_corr_based_graph flag\n",
        "            if use_corr_based_graph:\n",
        "                supports = [calculate_correlation_adjacency_batch(encoder_inputs).to(device)]\n",
        "\n",
        "            outputs = model(encoder_inputs, decoder_inputs, supports)\n",
        "            loss = criterion(outputs, decoder_inputs)\n",
        "            mae = mean_absolute_error(outputs, decoder_inputs)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            val_mae += mae.item()\n",
        "\n",
        "    return val_loss / len(val_loader), val_mae / len(val_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wDEHGGgUaczQ"
      },
      "outputs": [],
      "source": [
        "# Define graph types for experimentation\n",
        "graph_types = ['euclidean', 'road_network', 'fully_connected', 'identity', 'corr_based']\n",
        "results = {}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_nodes = sensor_locations.shape[0]\n",
        "\n",
        "# Dictionary to store adjacency matrices for each graph type\n",
        "adjacency_matrices = {}\n",
        "\n",
        "# TODO: Calculate adjacency matrix for each graph type and store in `adjacency_matrices`\n",
        "\n",
        "# === Parameters for similarity thresholds ===\n",
        "# For road network distance (in meters): paper uses κ = 1000m\n",
        "road_threshold = 1000  \n",
        "\n",
        "# For euclidean distance in lat/lon (~0.01 degrees ~ 1.1km)\n",
        "# Use quantile as heuristic if raw distance unknown\n",
        "coord_array = sensor_locations[['latitude', 'longitude']].values\n",
        "euclid_raw_dist = distance_matrix(coord_array, coord_array)\n",
        "euclid_threshold = np.quantile(euclid_raw_dist, 0.25)  # keep top 25% neighbors\n",
        "\n",
        "# 1. Euclidean Distance Adjacency\n",
        "# adjacency_matrices['euclidean'] = ...\n",
        "adjacency_matrices['euclidean'] = torch.tensor(\n",
        "    calculate_euclidean_adjacency(sensor_locations, threshold=euclid_threshold),\n",
        "    dtype=torch.float32\n",
        ").to(device)\n",
        "\n",
        "# 2. Road Network Adjacency\n",
        "# adjacency_matrices['road_network'] = ...\n",
        "adjacency_matrices['road_network'] = torch.tensor(\n",
        "    calculate_road_network_adjacency(sensor_locations, threshold=road_threshold),\n",
        "    dtype=torch.float32\n",
        ").to(device)\n",
        "\n",
        "# 3. Fully Connected Graph\n",
        "# adjacency_matrices['fully_connected'] = ...\n",
        "adjacency_matrices['fully_connected'] = torch.tensor(\n",
        "    calculate_fully_connected_adjacency(num_nodes),\n",
        "    dtype=torch.float32\n",
        ").to(device)\n",
        "\n",
        "# 4. Identity (Fully Disconnected) Graph\n",
        "# adjacency_matrices['identity'] = ...\n",
        "adjacency_matrices['identity'] = torch.tensor(\n",
        "    calculate_identity_adjacency(num_nodes),\n",
        "    dtype=torch.float32\n",
        ").to(device)\n",
        "\n",
        "# 5. Correlation-Based Adjacency (Dynamic, calculated per batch)\n",
        "# adjacency_matrices['corr_based'] = None  # Set to None for dynamic calculation in training loop\n",
        "adjacency_matrices['corr_based'] = None  # computed dynamically in training loop\n",
        "# Please note that you need to calculate the correlation-based adjacency matrix in the training loop by setting use_corr_based_graph flag set to True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcxIy0b9kbpy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training with euclidean adjacency matrix...\n",
            "\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 0/20 | Train Loss: 2208.2547 | Val Loss: 1047.0596 | Val MAE: 30.4701\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 1/20 | Train Loss: 583.0985 | Val Loss: 328.5390 | Val MAE: 15.7431\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 2/20 | Train Loss: 289.7890 | Val Loss: 263.8205 | Val MAE: 12.3961\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 3/20 | Train Loss: 283.4658 | Val Loss: 257.2377 | Val MAE: 12.2930\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 4/20 | Train Loss: 271.6376 | Val Loss: 259.9541 | Val MAE: 12.5967\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 5/20 | Train Loss: 271.4390 | Val Loss: 247.4821 | Val MAE: 11.1545\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 6/20 | Train Loss: 264.3861 | Val Loss: 243.9190 | Val MAE: 11.0972\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 7/20 | Train Loss: 261.7848 | Val Loss: 243.4460 | Val MAE: 11.1422\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 8/20 | Train Loss: 261.8601 | Val Loss: 243.4918 | Val MAE: 11.0557\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 9/20 | Train Loss: 259.7823 | Val Loss: 243.4100 | Val MAE: 11.0632\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 10/20 | Train Loss: 258.7086 | Val Loss: 243.4589 | Val MAE: 10.9715\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 11/20 | Train Loss: 255.9072 | Val Loss: 243.3937 | Val MAE: 11.0107\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 12/20 | Train Loss: 253.4799 | Val Loss: 243.3881 | Val MAE: 11.0082\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 13/20 | Train Loss: 251.7956 | Val Loss: 243.3499 | Val MAE: 11.0413\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 14/20 | Train Loss: 250.5006 | Val Loss: 243.3265 | Val MAE: 11.0807\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 15/20 | Train Loss: 249.7378 | Val Loss: 243.3284 | Val MAE: 11.0894\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 16/20 | Train Loss: 251.4044 | Val Loss: 243.5390 | Val MAE: 11.1307\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 17/20 | Train Loss: 250.6007 | Val Loss: 243.3489 | Val MAE: 10.9658\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 18/20 | Train Loss: 248.7894 | Val Loss: 243.3233 | Val MAE: 11.0756\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 19/20 | Train Loss: 247.7821 | Val Loss: 243.2976 | Val MAE: 11.0081\n",
            "torch.Size([17, 207, 207]) 1\n",
            "✅ Finished [euclidean] | Best Val Loss: 243.2976 | Test Loss: 264.8373 | Test MAE: 11.2633\n",
            "\n",
            "Training with road_network adjacency matrix...\n",
            "\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 0/20 | Train Loss: 1492.2171 | Val Loss: 492.3460 | Val MAE: 20.8688\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 1/20 | Train Loss: 233.2680 | Val Loss: 87.8064 | Val MAE: 7.5767\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 2/20 | Train Loss: 78.9111 | Val Loss: 44.8900 | Val MAE: 4.3788\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 3/20 | Train Loss: 65.7486 | Val Loss: 41.1700 | Val MAE: 3.8947\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 4/20 | Train Loss: 63.2670 | Val Loss: 38.2820 | Val MAE: 3.5764\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 5/20 | Train Loss: 62.1427 | Val Loss: 38.1690 | Val MAE: 3.5596\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 6/20 | Train Loss: 61.4721 | Val Loss: 37.1001 | Val MAE: 3.4366\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 7/20 | Train Loss: 61.1674 | Val Loss: 38.7596 | Val MAE: 3.7485\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 8/20 | Train Loss: 60.7374 | Val Loss: 37.1760 | Val MAE: 3.5514\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 9/20 | Train Loss: 60.1396 | Val Loss: 37.1702 | Val MAE: 3.3620\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 10/20 | Train Loss: 59.7940 | Val Loss: 36.5681 | Val MAE: 3.3718\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 11/20 | Train Loss: 59.5756 | Val Loss: 36.4886 | Val MAE: 3.3906\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 12/20 | Train Loss: 58.9659 | Val Loss: 36.7796 | Val MAE: 3.5180\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 13/20 | Train Loss: 58.8343 | Val Loss: 36.1836 | Val MAE: 3.3355\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 14/20 | Train Loss: 58.0537 | Val Loss: 37.0670 | Val MAE: 3.4035\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 15/20 | Train Loss: 57.6704 | Val Loss: 36.0944 | Val MAE: 3.2810\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 16/20 | Train Loss: 57.3069 | Val Loss: 37.4999 | Val MAE: 3.5865\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 17/20 | Train Loss: 56.7613 | Val Loss: 36.3806 | Val MAE: 3.2262\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 18/20 | Train Loss: 56.3236 | Val Loss: 35.8471 | Val MAE: 3.1970\n",
            "torch.Size([13, 207, 207]) 1\n",
            "torch.Size([16, 207, 207]) 1\n",
            "Epoch 19/20 | Train Loss: 55.9227 | Val Loss: 36.9891 | Val MAE: 3.3633\n",
            "torch.Size([17, 207, 207]) 1\n",
            "✅ Finished [road_network] | Best Val Loss: 35.8471 | Test Loss: 39.0538 | Test MAE: 3.4142\n",
            "\n",
            "Training with fully_connected adjacency matrix...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters - TODO: You need to tune these and achieve a good balance between performance / train time\n",
        "hidden_dim = 64\n",
        "learning_rate = 0.001\n",
        "max_diffusion_step = 2 # You can leave this as is\n",
        "num_rnn_layers = 1\n",
        "dropout = 0.3\n",
        "num_epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "# Loop over each graph type to train and evaluate the model\n",
        "for graph_type in graph_types:\n",
        "    print(f\"\\nTraining with {graph_type} adjacency matrix...\\n\")\n",
        "\n",
        "    # TODO: Retrieve the adjacency matrix for the current `graph_type`\n",
        "    # Supports is the adjacency matrix, with the shape [(batch_size, num_node, num_nodes)]\n",
        "    use_corr_based_graph = (graph_type == 'corr_based')\n",
        "\n",
        "    if use_corr_based_graph:\n",
        "        supports = None  # handled dynamically in train_epoch\n",
        "    else:\n",
        "        supports = [adjacency_matrices[graph_type].repeat(batch_size, 1, 1).to(device)]\n",
        "\n",
        "\n",
        "    # Set up the model and optimizer\n",
        "    model = DCRNNModel_nextTimePred(\n",
        "        num_nodes=num_nodes,\n",
        "        hidden_dim=hidden_dim,\n",
        "        input_dim=1,\n",
        "        output_dim=1,\n",
        "        max_diffusion_step=max_diffusion_step,\n",
        "        num_rnn_layers=num_rnn_layers,\n",
        "        dropout=dropout,\n",
        "        use_curriculum_learning=False,\n",
        "        device=device\n",
        "    ).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Track best validation loss and model state for each graph type\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    # Training loop for multiple epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # TODO: Train model for one epoch and calculate training loss, e.g.,\n",
        "        train_loss = train_epoch(model, train_loader, supports, optimizer, device, use_corr_based_graph)\n",
        "\n",
        "        # TODO: Evaluate model on validation set and calculate validation loss and MAE\n",
        "        # val_loss, val_mae = validate_epoch(...)\n",
        "        val_loss, val_mae = validate_epoch(model, val_loader, supports, device, use_corr_based_graph)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val MAE: {val_mae:.4f}\")\n",
        "\n",
        "        # TODO: Save the model state if validation loss improves\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "    # TODO: Store the best validation loss and model state for the current graph type in `results`\n",
        "    # results[graph_type] = {\n",
        "    #     \"best_val_loss\": best_val_loss,\n",
        "    # \"best_model_state\": best_model_state\n",
        "    # }\n",
        "\n",
        "\n",
        "    # Load the best model state for the current graph type\n",
        "    model.load_state_dict(best_model_state)\n",
        "\n",
        "    # TODO: Test the model on the test set and calculate test loss and MAE\n",
        "    # test_loss, test_mae = validate_epoch(...)\n",
        "    test_loss, test_mae = validate_epoch(model, test_loader, supports, device, use_corr_based_graph)\n",
        "\n",
        "    print(f\"✅ Finished [{graph_type}] | Best Val Loss: {best_val_loss:.4f} | Test Loss: {test_loss:.4f} | Test MAE: {test_mae:.4f}\")\n",
        "\n",
        "    # TODO: Store the best validation loss, test loss, and model state for the current graph type in `results`\n",
        "    results[graph_type] = {\n",
        "        \"best_val_loss\": best_val_loss,\n",
        "        \"test_loss\": test_loss,\n",
        "        \"test_mae\": test_mae,\n",
        "        \"best_model_state\": best_model_state\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGaK0xP2lzl4"
      },
      "source": [
        "## Discussion\n",
        "TODO: For this part, please:\n",
        "- Compare results across graph types and summarize your findings. You can visualize the test/validation performance for different graph types to support your findings.\n",
        "- Discuss which graph type performed best on the test set, and justify why.\n",
        "- Discuss why some adjacency matrices resulted in better performacne compared to the other ones.\n",
        "- Describe how you tuned the training hyperparameters.\n",
        "- In case you had any interesting observations or faced some challenges, please also describe those."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxPwBhIX1bB4"
      },
      "source": [
        "## Submission Instructions\n",
        "Please submit your completed Jupyter Notebook file as `HW3_YourName_USC_ID.ipynb` on Brightspace. Make sure all the cells have been successfully executed and the outputs are visible."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "spatial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
